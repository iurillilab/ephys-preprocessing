{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from pathlib import Path\n",
    "from neuroconv import ConverterPipe\n",
    "from neuroconv.datainterfaces import DeepLabCutInterface, VideoInterface\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig_folder = Path(\"/Users/vigji/Desktop/test_synch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_in_folder(folder, pattern):\n",
    "    return next(folder.glob(pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos and DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file already exists in /Users/vigji/Desktop/test_mpa_dir/P02_MPAOPTO_LP/e02_ephys-contrapag-stim/M21/20240421/165242/config.yaml.\n",
      "268646\n",
      "Config file already exists in /Users/vigji/Desktop/test_mpa_dir/P02_MPAOPTO_LP/e02_ephys-contrapag-stim/M21/20240421/165242/config.yaml.\n",
      "268646\n"
     ]
    }
   ],
   "source": [
    "def _copy_and_update_config_file(config_file_path, video_file_path, dest_dir=None, overwrite=False):\n",
    "    # Copy config file to data folder:\n",
    "    config_file_path = Path(config_file_path)\n",
    "    video_file_path = Path(video_file_path)\n",
    "    if dest_dir is None:\n",
    "        dest_dir = video_file_path.parent\n",
    "    else:\n",
    "        dest_dir = Path(dest_dir)\n",
    "\n",
    "    config_file_path_copy = dest_dir / config_file_path.name\n",
    "\n",
    "    if not overwrite and config_file_path_copy.exists():\n",
    "        print(f\"Config file already exists in {config_file_path_copy}.\")\n",
    "        return config_file_path_copy\n",
    "\n",
    "    config_file_text = config_file_path.read_text()\n",
    "    # find crop by looking for content in between crop: and \\n:\n",
    "    crop = config_file_text.split(\"crop: \")[1].split(\"\\n\")[0]\n",
    "    config_file_text = config_file_text.replace(\"\\nvideo_sets:\\n  \", \n",
    "                            f\"\\nvideo_sets:\\n  {video_file_path}:\\n    crop: {crop}\\n  \")\n",
    "    config_file_path_copy.write_text(config_file_text)\n",
    "\n",
    "    return config_file_path_copy\n",
    "\n",
    "mid = \"M21\"\n",
    "day = \"20240421\"\n",
    "ses = \"165242\"\n",
    "data_folder = Path(f\"/Users/vigji/Desktop/test_mpa_dir/P02_MPAOPTO_LP/e02_ephys-contrapag-stim/{mid}/{day}/{ses}\")\n",
    "video_data = {\"eye\": {\"name\": \"EyeCamera\",\n",
    "                      \"description\": \"Magnified view of the animal's pupil.\", \n",
    "                      \"dlc_model_path\": \"/Volumes/SystemsNeuroBiology/SNeuroBiology_shared/DLC_models/eye-pupil-Luigi Petrucco-2023-12-16/config.yaml\"},\n",
    "              \"top\": {\"name\": \"TopCamera\",\n",
    "                      \"description\": \"Top view of the animal's head and body in the setup.\", \n",
    "                      \"dlc_model_path\": \"/Volumes/SystemsNeuroBiology/SNeuroBiology_shared/DLC_models/top-cam-Luigi Petrucco-2023-12-16/config.yaml\"},\n",
    "                      }\n",
    "\n",
    "path_to_save_nwbfile = data_folder / f\"{mid}_{day}_{ses}.nwb\" \n",
    "\n",
    "dlc_interfaces = []\n",
    "video_interfaces = []\n",
    "video_dicts = []\n",
    "for i_cam, camera in  enumerate([\"eye\", \"top\"]):\n",
    "    dlc_file_path = _find_in_folder(data_folder, f\"*{camera.title()}*.h5\")\n",
    "    video_file_path = _find_in_folder(data_folder, f\"*{dlc_file_path.stem.split('DLC')[0]}*.avi\")\n",
    "    timestamps_file_path = _find_in_folder(data_folder, f\"*{dlc_file_path.stem.split('DLC')[0][-10:]}*.csv\")\n",
    "    config_file_path = video_data[camera][\"dlc_model_path\"]\n",
    "    # update config file with video path:\n",
    "    config_file_path = _copy_and_update_config_file(config_file_path, video_file_path)\n",
    "\n",
    "    # load framerate csv:\n",
    "    framerate_df = pd.read_csv(timestamps_file_path)\n",
    "    # convert to datetime the Timestamp column strings to seconds from first timestamp:\n",
    "    timestamps = pd.to_datetime(framerate_df[\"Timestamp\"])\n",
    "    timestamps = (timestamps - timestamps[0]).dt.total_seconds().values\n",
    "\n",
    "    dlc_interface = DeepLabCutInterface(file_path=dlc_file_path, config_file_path=config_file_path, subject_name=mid, verbose=False)\n",
    "    dlc_interface.set_aligned_timestamps(timestamps)\n",
    "\n",
    "    dlc_interfaces.append(dlc_interface)\n",
    "\n",
    "    video_interface = VideoInterface(file_paths=[video_file_path], \n",
    "                                     # timestamps=[timestamps],\n",
    "                                     verbose=False, \n",
    "                                     metadata_key_name=video_data[camera][\"name\"])\n",
    "    print(len(timestamps))\n",
    "    video_interface.set_aligned_timestamps([timestamps])\n",
    "    video_interfaces.append(video_interface)\n",
    "    video_dict = {\"file_path\": video_file_path, \n",
    "                  \"description\": video_data[camera][\"description\"], \n",
    "                  \"name\": video_data[camera][\"name\"],\n",
    "                  \"interface_num\": f\"00{i_cam+1}\",\n",
    "                  \"timestamps\": timestamps,}\n",
    "    video_dicts.append(video_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video_interface = VideoInterface(file_paths=[v[\"file_path\"] for v in video_dicts], verbose=False)\n",
    "video_interface.set_aligned_timestamps([v[\"timestamps\"] for v in video_dicts])\n",
    "video_metadata = video_interface.get_metadata()\n",
    "for video_dict, cam_metadata in zip(video_dicts, video_metadata[\"Behavior\"][\"Videos\"]):\n",
    "    cam_metadata.update({k: video_dict[k] for k in [\"name\", \"description\"]})\n",
    "video_metadata.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata is valid!\n",
      "conversion_options is valid!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vigji/code/DLC2NWB/dlc2nwb/utils.py:101: UserWarning: Replacing cv2 timestamps returned as 0: 0.003350%\n",
      "  warnings.warn( # warns user of percent of 0 frames\n",
      "/Users/vigji/code/neuroconv/src/neuroconv/datainterfaces/behavior/deeplabcut/deeplabcutdatainterface.py:49: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df_animal = df.groupby(level=\"individuals\", axis=1).get_group(individual_name)\n",
      "/Users/vigji/code/DLC2NWB/dlc2nwb/utils.py:204: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  for kpt, xyp in df_animal.groupby(level=\"bodyparts\", axis=1, sort=False):\n",
      "/Users/vigji/code/DLC2NWB/dlc2nwb/utils.py:181: UserWarning: The video file corresponding to /Users/vigji/Desktop/test_mpa_dir/M21/20240421/165242/TopCamera__video_2024-04-21T16_52_14DLC_resnet50_top-camDec16shuffle1_7000.h5 could not be found...\n",
      "  warnings.warn(f\"The video file corresponding to {h5file} could not be found...\")\n",
      "/Users/vigji/code/neuroconv/src/neuroconv/datainterfaces/behavior/deeplabcut/deeplabcutdatainterface.py:49: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df_animal = df.groupby(level=\"individuals\", axis=1).get_group(individual_name)\n",
      "/Users/vigji/code/DLC2NWB/dlc2nwb/utils.py:204: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  for kpt, xyp in df_animal.groupby(level=\"bodyparts\", axis=1, sort=False):\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_fiber-l': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_fiber-r': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_nose-r': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_nose': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_nose-l': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_cube-l': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_cube-mid': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/pynwb/base.py:203: UserWarning: PoseEstimationSeries 'M21_cube-r': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "/Users/vigji/miniconda3/envs/lab-env/lib/python3.10/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'PoseEstimation/dimensions': Value with data type int64 is being converted to data type uint64 (min specification: uint8).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file saved at /Users/vigji/Desktop/test_mpa_dir/M21/20240421/165242/M21_20240421_165242.nwb!\n"
     ]
    }
   ],
   "source": [
    "conv_pipe = ConverterPipe([*video_interfaces, *dlc_interfaces, ], \n",
    "                          verbose=True)  \n",
    "\n",
    "# remove file if it exists:\n",
    "if path_to_save_nwbfile.exists():\n",
    "    path_to_save_nwbfile.unlink()\n",
    "\n",
    "metadata = conv_pipe.get_metadata()\n",
    "# For data provenance we add the time zone information to the conversion\n",
    "session_start_time = datetime(2020, 1, 1, 12, 30, 0, tzinfo=ZoneInfo(\"US/Pacific\"))\n",
    "metadata[\"NWBFile\"].update(session_start_time=session_start_time)\n",
    "# pprint.pprint(metadata.to_dict())\n",
    "# Choose a path for saving the nwb file and run the conversion\n",
    "conversion_options = {f\"DeepLabCutInterface{v['interface_num']}\": dict(container_name=v[\"name\"]) for v in video_dicts}\n",
    "conv_pipe.run_conversion(nwbfile_path=path_to_save_nwbfile, metadata=metadata, conversion_options=conversion_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_path = video_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "df must contain a column named 'start_time'. Existing columns: ['Value', 'Timestamp']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[391], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNWBFile\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(session_start_time\u001b[38;5;241m=\u001b[39msession_start_time)\n\u001b[1;32m     16\u001b[0m nwbfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_save_nwbfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# This should be something like: \"./saved_file.nwb\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m nwbfile \u001b[38;5;241m=\u001b[39m \u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnwbfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnwbfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/neuroconv/src/neuroconv/basedatainterface.py:176\u001b[0m, in \u001b[0;36mBaseDataInterface.run_conversion\u001b[0;34m(self, nwbfile_path, nwbfile, metadata, overwrite, backend, backend_configuration, **conversion_options)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m make_or_load_nwbfile(\n\u001b[1;32m    168\u001b[0m     nwbfile_path\u001b[38;5;241m=\u001b[39mnwbfile_path,\n\u001b[1;32m    169\u001b[0m     nwbfile\u001b[38;5;241m=\u001b[39mnwbfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    174\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m nwbfile_out:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_nwbfile_provided:\n\u001b[0;32m--> 176\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_to_nwbfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnwbfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnwbfile_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconversion_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend_configuration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         backend_configuration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_backend_configuration(nwbfile\u001b[38;5;241m=\u001b[39mnwbfile_out, backend\u001b[38;5;241m=\u001b[39mbackend)\n",
      "File \u001b[0;32m~/code/neuroconv/src/neuroconv/datainterfaces/text/timeintervalsinterface.py:144\u001b[0m, in \u001b[0;36mTimeIntervalsInterface.add_to_nwbfile\u001b[0;34m(self, nwbfile, metadata, tag, column_name_mapping, column_descriptions)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03mRun the NWB conversion for the instantiated data interface.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m metadata \u001b[38;5;241m=\u001b[39m metadata \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_metadata()\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_intervals \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_df_to_time_intervals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_name_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_name_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_descriptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_descriptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTimeIntervals\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m nwbfile\u001b[38;5;241m.\u001b[39madd_time_intervals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_intervals)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nwbfile\n",
      "File \u001b[0;32m~/code/neuroconv/src/neuroconv/tools/text.py:52\u001b[0m, in \u001b[0;36mconvert_df_to_time_intervals\u001b[0;34m(df, table_name, table_description, column_name_mapping, column_descriptions)\u001b[0m\n\u001b[1;32m     50\u001b[0m time_intervals \u001b[38;5;241m=\u001b[39m TimeIntervals(name\u001b[38;5;241m=\u001b[39mtable_name, description\u001b[38;5;241m=\u001b[39mtable_description)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf must contain a column named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Existing columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_list()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[1;32m     54\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mto_numpy(), np\u001b[38;5;241m.\u001b[39mnan]\n",
      "\u001b[0;31mValueError\u001b[0m: df must contain a column named 'start_time'. Existing columns: ['Value', 'Timestamp']"
     ]
    }
   ],
   "source": [
    "from neuroconv.datainterfaces import CsvTimeIntervalsInterface\n",
    "from datetime import datetime\n",
    "debug_plots = False\n",
    "\n",
    "file_path = _find_in_folder(data_folder, \"*laser-log*.csv\")\n",
    "\n",
    "# Change the file_path to the location of the file in your system\n",
    "interface = CsvTimeIntervalsInterface(file_path=file_path, verbose=False)\n",
    "\n",
    "# Extract what metadata we can from the source files\n",
    "metadata = interface.get_metadata()\n",
    "# Add the time zone information to the conversion\n",
    "session_start_time = datetime(2020, 1, 1, 12, 30, 0, tzinfo=ZoneInfo(\"US/Pacific\"))\n",
    "metadata[\"NWBFile\"] = dict(session_start_time=session_start_time)\n",
    "\n",
    "nwbfile_path = f\"{path_to_save_nwbfile}\" # This should be something like: \"./saved_file.nwb\"\n",
    "nwbfile = interface.run_conversion(nwbfile_path=nwbfile_path, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get timestamps from digital logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "from labnpx.digital_signal import DigitalSignal\n",
    "from labnpx.barcode_signal import BarcodeSignal\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def _read_oephys_datetime(oephys_folder, timezone=\"Europe/Rome\"):\n",
    "    \"\"\"Read the datetime of the recording from the sync_messages.txt file in the oephys folder.\"\"\"\n",
    "\n",
    "    synch_txt_file = _find_in_folder(oephys_folder, \"*/*/*/sync_messages.txt\")\n",
    "\n",
    "    with open(synch_txt_file, \"r\") as f:\n",
    "        line = f.readline()\n",
    "\n",
    "    # get content between : and \\n:\n",
    "    start_msec_utc = int(line.split(\": \")[1].split(\"\\n\")[0])\n",
    "    return datetime.fromtimestamp(start_msec_utc / 1000, ZoneInfo(timezone))\n",
    "\n",
    "def _load_signals_from_daq_interface(interface, dwnsamp=4):\n",
    "    CHANNELS_MAP = {0: 'frames', 1: 'laser', 2: '-', 3: 'motor', 4: 'barcode', 5: '-', 6: '-', 7: '-'}\n",
    "    THR = 10000  # for analog reading of digital signals\n",
    "\n",
    "    fs = interface.sampling_frequency\n",
    "\n",
    "    assert fs % dwnsamp == 0, \"The downsampling factor must be a divisor of the original sampling frequency.\"\n",
    "    target_fs = int(fs / dwnsamp)\n",
    "\n",
    "    traces_array = np.array(digital_traces_interface.get_traces()[::dwnsamp, :])\n",
    "\n",
    "    # Create a DigitalSignal objects dictionary for valid channels:\n",
    "    digital_signals = {}\n",
    "    for idx in range(8):\n",
    "        if CHANNELS_MAP[idx] != '-':\n",
    "            digital_signals[CHANNELS_MAP[idx]] = DigitalSignal(traces_array[:, idx] > THR, fs=target_fs)\n",
    "    \n",
    "    return digital_signals\n",
    "\n",
    "def _validate_log_timestamps(trials_df, trials_digital_onsets, tolerance=0.1):\n",
    "    \"\"\"Function to validate trial timestamps from csv log and digital signals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trials_df : pd.DataFrame\n",
    "        Dataframe with trial timestamps, with a \"Timestamp\" column.\n",
    "    trials_digital_onsets : np.ndarray\n",
    "        Array with trial onsets from digital signals.\n",
    "    tolerance : float, optional\n",
    "        Max tolerated time mismatch, by default 0.1\n",
    "    \"\"\"\n",
    "    assert len(trials_df) == len(trials_digital_onsets), \"Number of trials in laser log does not match number of trials in digital signals\"\n",
    "\n",
    "    # convert timestamp from 2024-04-21T16:58:03.6325504+02:00 format:\n",
    "    trial_onsets_df = pd.to_datetime(trials_df[\"serial-timestamp\"])\n",
    "    trial_intervals_df = trial_onsets_df.diff().dt.total_seconds().values[1:]\n",
    "    # compare log and digital signal derived trial intervals:\n",
    "    assert np.allclose(trial_intervals_df, np.diff(trials_digital_onsets), atol=tolerance), \\\n",
    "        \"Trial intervals from log and digital signals do not match\"\n",
    "\n",
    "\n",
    "oephys_folder = _find_in_folder(data_folder, \"NPX/[0-9]*\")\n",
    "digital_traces_interface = si.read_openephys(oephys_folder, stream_name=\"Record Node 103#NI-DAQmx-102.USB-6212 (BNC)\")\n",
    "oephys_datetime = _read_oephys_datetime(oephys_folder)\n",
    "\n",
    "digital_signals = _load_signals_from_daq_interface(digital_traces_interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if debug_plots:\n",
    "    t_lims = (1000, 1060)\n",
    "    t_slice = slice(target_fs*t_lims[0], target_fs*t_lims[1])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for idx in range(8):\n",
    "        plt.plot(traces_array[t_slice, idx]+20000*idx, lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get camera frames triggers, and raise relative warnings if needed\n",
    "camera_timestamps = digital_signals[\"frames\"].onsets_times\n",
    "assert camera_timestamps[0] > 1, \"Camera frames trigger starts too early, could have missed something\"\n",
    "# assert camera_timestamps[-1] < (digital_signals[\"frames\"].duration - 1), \"Camera frames trigger ends too late, could have missed something\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSUMED_TRIAL_LENGTH_S = 6.2\n",
    "MIN_TRIAL_DISTANCE_S = 1\n",
    "TOLERANCE_S = 0.3\n",
    "\n",
    "def _load_laser_log_csv(data_folder, digital_log_signal, \n",
    "                        min_trial_distance_s=MIN_TRIAL_DISTANCE_S, tolerance_s=TOLERANCE_S):\n",
    "    \"\"\"Load laser log csv file and validate and add columns with digital signal timestamps.\"\"\"\n",
    "    COLUMN_NAME_REMAP = {\"Timestamp\": \"serial-timestamp\"}\n",
    "    \n",
    "    laser_log_file = _find_in_folder(data_folder, \"*laser-log*.csv\")\n",
    "    df = pd.read_csv(laser_log_file)\n",
    "    df.rename(columns=COLUMN_NAME_REMAP, inplace=True)\n",
    "\n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "    for i, content in enumerate([\"frequency\", \"pulse-width_ms\", \"stim-duration_ms\"]):\n",
    "        df[content] = df[\"Value\"].apply(lambda x: x.split(\";\")[i])\n",
    "\n",
    "    # get laser triggers\n",
    "    laser_onsets = digital_log_signal.onsets_times\n",
    "    laser_offsets = digital_log_signal.offsets_times\n",
    "\n",
    "    # trial onsets/offsets are the onsets which distance to the previous/next onset/offset \n",
    "    # is greater than 0.5 s, plus the first onset.\n",
    "    laser_trial_onsets = np.concatenate([[laser_onsets[0]], laser_onsets[1:][np.diff(laser_onsets) > min_trial_distance_s]])\n",
    "    laset_trial_offsets = np.concatenate([laser_offsets[:-1][np.diff(laser_onsets) > min_trial_distance_s], [laser_offsets[-1]]])\n",
    "\n",
    "    # read laser log and cross check number of trials:\n",
    "\n",
    "    _validate_log_timestamps(df, laser_trial_onsets, tolerance=tolerance_s)\n",
    "\n",
    "    df[\"start_time_bnc-time\"] = laser_trial_onsets\n",
    "    df[\"end_time_bnc-time\"] = laset_trial_offsets\n",
    "\n",
    "    return df.drop(\"Value\", axis=1)\n",
    "\n",
    "laser_log_df = _load_laser_log_csv(data_folder, digital_signals[\"laser\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor-order</th>\n",
       "      <th>radius_cm</th>\n",
       "      <th>theta_rad</th>\n",
       "      <th>serial-timestamp</th>\n",
       "      <th>start_time_bnc-time</th>\n",
       "      <th>end_time_bnc-time</th>\n",
       "      <th>approach-end_bnc-time</th>\n",
       "      <th>depart-start_bnc-time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.769911</td>\n",
       "      <td>2024-04-21T16:58:03.6325504+02:00</td>\n",
       "      <td>373.6714</td>\n",
       "      <td>379.9441</td>\n",
       "      <td>373.8714</td>\n",
       "      <td>379.7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.932153</td>\n",
       "      <td>2024-04-21T16:58:23.6199936+02:00</td>\n",
       "      <td>393.6567</td>\n",
       "      <td>399.8835</td>\n",
       "      <td>393.8566</td>\n",
       "      <td>399.6835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>2024-04-21T16:58:43.6440960+02:00</td>\n",
       "      <td>413.6782</td>\n",
       "      <td>419.9015</td>\n",
       "      <td>413.8781</td>\n",
       "      <td>419.7015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.094395</td>\n",
       "      <td>2024-04-21T16:59:03.6641664+02:00</td>\n",
       "      <td>433.6963</td>\n",
       "      <td>439.9124</td>\n",
       "      <td>433.8963</td>\n",
       "      <td>439.7124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.094395</td>\n",
       "      <td>2024-04-21T16:59:23.6854272+02:00</td>\n",
       "      <td>453.7153</td>\n",
       "      <td>459.9296</td>\n",
       "      <td>453.9153</td>\n",
       "      <td>459.7297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>2024-04-21T18:32:27.8405248+02:00</td>\n",
       "      <td>6037.2332</td>\n",
       "      <td>6043.4512</td>\n",
       "      <td>6037.4332</td>\n",
       "      <td>6043.2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.932153</td>\n",
       "      <td>2024-04-21T18:32:47.8625536+02:00</td>\n",
       "      <td>6057.2529</td>\n",
       "      <td>6063.4626</td>\n",
       "      <td>6057.4528</td>\n",
       "      <td>6063.2626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>2024-04-21T18:33:07.8735744+02:00</td>\n",
       "      <td>6077.2615</td>\n",
       "      <td>6083.4784</td>\n",
       "      <td>6077.4614</td>\n",
       "      <td>6083.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.094395</td>\n",
       "      <td>2024-04-21T18:33:27.8854784+02:00</td>\n",
       "      <td>6097.2707</td>\n",
       "      <td>6103.4806</td>\n",
       "      <td>6097.4707</td>\n",
       "      <td>6103.2806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>2024-04-21T18:33:47.8962176+02:00</td>\n",
       "      <td>6117.2796</td>\n",
       "      <td>6123.4950</td>\n",
       "      <td>6117.4796</td>\n",
       "      <td>6123.2950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     motor-order  radius_cm  theta_rad                   serial-timestamp  \\\n",
       "1              2        3.0   3.769911  2024-04-21T16:58:03.6325504+02:00   \n",
       "3              1        4.5   2.932153  2024-04-21T16:58:23.6199936+02:00   \n",
       "5              2        3.0   4.188790  2024-04-21T16:58:43.6440960+02:00   \n",
       "7              1        6.0   2.094395  2024-04-21T16:59:03.6641664+02:00   \n",
       "9              1        6.0   2.094395  2024-04-21T16:59:23.6854272+02:00   \n",
       "..           ...        ...        ...                                ...   \n",
       "567            2        4.5   4.188790  2024-04-21T18:32:27.8405248+02:00   \n",
       "569            1        6.0   2.932153  2024-04-21T18:32:47.8625536+02:00   \n",
       "571            2        3.0   4.188790  2024-04-21T18:33:07.8735744+02:00   \n",
       "573            1        3.0   2.094395  2024-04-21T18:33:27.8854784+02:00   \n",
       "575            2        4.5   4.188790  2024-04-21T18:33:47.8962176+02:00   \n",
       "\n",
       "     start_time_bnc-time  end_time_bnc-time  approach-end_bnc-time  \\\n",
       "1               373.6714           379.9441               373.8714   \n",
       "3               393.6567           399.8835               393.8566   \n",
       "5               413.6782           419.9015               413.8781   \n",
       "7               433.6963           439.9124               433.8963   \n",
       "9               453.7153           459.9296               453.9153   \n",
       "..                   ...                ...                    ...   \n",
       "567            6037.2332          6043.4512              6037.4332   \n",
       "569            6057.2529          6063.4626              6057.4528   \n",
       "571            6077.2615          6083.4784              6077.4614   \n",
       "573            6097.2707          6103.4806              6097.4707   \n",
       "575            6117.2796          6123.4950              6117.4796   \n",
       "\n",
       "     depart-start_bnc-time  \n",
       "1                 379.7441  \n",
       "3                 399.6835  \n",
       "5                 419.7015  \n",
       "7                 439.7124  \n",
       "9                 459.7297  \n",
       "..                     ...  \n",
       "567              6043.2512  \n",
       "569              6063.2626  \n",
       "571              6083.2784  \n",
       "573              6103.2806  \n",
       "575              6123.2950  \n",
       "\n",
       "[288 rows x 8 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _load_motor_log_csv(data_folder, digital_log_signal, assumed_trial_len_s=ASSUMED_TRIAL_LENGTH_S,\n",
    "                        tolerance_s=TOLERANCE_S):\n",
    "    \"\"\"Load motor log csv file and validate and add columns for digital signal timestamps.\"\"\"\n",
    "\n",
    "    # fix log column names:\n",
    "    COLUMN_NAME_REMAP = {\"Value.Radius\": \"motor-order\", \n",
    "                         \"Value.Theta\": \"radius_cm\", \n",
    "                         \"Value.Direction\": \"theta_rad\",\n",
    "                         \"Timestamp\": \"serial-timestamp\"}\n",
    "\n",
    "    # get motor triggers\n",
    "    motor_onsets = digital_log_signal.onsets_times\n",
    "    motor_offsets = digital_log_signal.offsets_times\n",
    "\n",
    "    # motor trial start times are one onset every 2 offsets; motor trial end times are one offset every 2 onsets.\n",
    "    # First movement is the initial reset and is not a trial.\n",
    "    motor_trial_onsets = motor_onsets[1::2]\n",
    "    motor_trial_offsets = motor_offsets[2::2]\n",
    "    approach_end = motor_offsets[1::2]\n",
    "    depart_start = motor_onsets[2::2]\n",
    "\n",
    "    # check that all trials are around 6.2 seconds long:\n",
    "    assert np.allclose(motor_trial_offsets - motor_trial_onsets, assumed_trial_len_s, atol=tolerance_s), \"Some motor trials are not around 6.2 seconds long\"\n",
    "\n",
    "    # double check with motor log:\n",
    "    motor_log_file = _find_in_folder(data_folder, \"*motor-log*.csv\")\n",
    "    df = pd.read_csv(motor_log_file)\n",
    "    df.rename(columns=COLUMN_NAME_REMAP, inplace=True)\n",
    "    # trials are one every two entries, skipping the first one:\n",
    "    df = df.loc[1::2, :]\n",
    "    assert len(motor_trial_onsets) == len(df), \"Number of trials in motor log does not match number of trials in digital signals\"\n",
    "\n",
    "    _validate_log_timestamps(df, motor_trial_onsets, tolerance=tolerance_s)\n",
    "\n",
    "    df[\"start_time_bnc-time\"] = motor_trial_onsets\n",
    "    df[\"end_time_bnc-time\"] = motor_trial_offsets\n",
    "    df[\"approach-end_bnc-time\"] = approach_end\n",
    "    df[\"depart-start_bnc-time\"] = depart_start\n",
    "\n",
    "    return df\n",
    "\n",
    "motor_log_df = _load_motor_log_csv(data_folder, digital_signals[\"motor\"])\n",
    "motor_log_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align timestamps to ephys log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373.2864"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _array_from_oephys_events(npx_traces_events, fs, pad_s=5, offset_s=0):\n",
    "    \"\"\"Create a boolean array from a list of events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : list\n",
    "        List of tuples with event onset and duration.\n",
    "    fs : int\n",
    "        Sampling frequency.\n",
    "    length : int\n",
    "        Length of the array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Boolean array with events.\n",
    "    \"\"\"\n",
    "    # create\n",
    "    barcodes_times = np.array([(evt[0]-offset_s, evt[1]) for evt in list(npx_traces_events.get_events('Neuropixels PXI Sync'))])\n",
    "    n_pts = int((barcodes_times[-1, 0] + pad_s)*fs)\n",
    "    barcodes_array = np.zeros(n_pts, dtype=bool)\n",
    "\n",
    "    for onset, duration in barcodes_times:\n",
    "        onset_idx = int(onset*barcodes_fs)\n",
    "        offset_idx = int((onset + duration)*barcodes_fs)\n",
    "        barcodes_array[onset_idx:offset_idx] = True\n",
    "\n",
    "    return barcodes_array\n",
    "\n",
    "\n",
    "# Read traces and synch events:\n",
    "npx1_traces_events = si.read_openephys_event(oephys_folder)\n",
    "barcodes_fs = digital_traces_interface.get_sampling_frequency()\n",
    "\n",
    "# Offset to be subtracted (first value of the probeA timestamps):\n",
    "recording1_interface = si.read_openephys(oephys_folder, stream_name=\"Record Node 103#Neuropix-PXI-100.ProbeA-AP\")\n",
    "offset_start = recording1_interface.get_time_info()[\"t_start\"]\n",
    "barcodes_array = _array_from_oephys_events(npx1_traces_events, barcodes_fs, offset_s=offset_start)\n",
    "\n",
    "barcode_signal_npx = BarcodeSignal(barcodes_array, fs=barcodes_fs)\n",
    "barcode_signal_nidaqx = BarcodeSignal(digital_signals[\"barcode\"].array, fs=digital_signals[\"barcode\"].fs)\n",
    "barcode_signal_npx.onsets_times[:5]\n",
    "barcode_signal_nidaqx.map_times_to(barcode_signal_npx, 0)\n",
    "offset_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor-order</th>\n",
       "      <th>radius_cm</th>\n",
       "      <th>theta_rad</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>approach-end</th>\n",
       "      <th>depart-start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.769911</td>\n",
       "      <td>373.644122</td>\n",
       "      <td>379.916842</td>\n",
       "      <td>373.844122</td>\n",
       "      <td>379.716841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.932153</td>\n",
       "      <td>393.629486</td>\n",
       "      <td>399.856306</td>\n",
       "      <td>393.829387</td>\n",
       "      <td>399.656305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>413.651050</td>\n",
       "      <td>419.874370</td>\n",
       "      <td>413.850951</td>\n",
       "      <td>419.674369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.094395</td>\n",
       "      <td>433.669214</td>\n",
       "      <td>439.885334</td>\n",
       "      <td>433.869215</td>\n",
       "      <td>439.685334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.094395</td>\n",
       "      <td>453.688279</td>\n",
       "      <td>459.902599</td>\n",
       "      <td>453.888279</td>\n",
       "      <td>459.702698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>6037.224098</td>\n",
       "      <td>6043.442118</td>\n",
       "      <td>6037.424099</td>\n",
       "      <td>6043.242118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.932153</td>\n",
       "      <td>6057.243863</td>\n",
       "      <td>6063.453583</td>\n",
       "      <td>6057.443763</td>\n",
       "      <td>6063.253582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>6077.252527</td>\n",
       "      <td>6083.469447</td>\n",
       "      <td>6077.452427</td>\n",
       "      <td>6083.269446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.094395</td>\n",
       "      <td>6097.261791</td>\n",
       "      <td>6103.471711</td>\n",
       "      <td>6097.461792</td>\n",
       "      <td>6103.271710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.188790</td>\n",
       "      <td>6117.270755</td>\n",
       "      <td>6123.486175</td>\n",
       "      <td>6117.470756</td>\n",
       "      <td>6123.286175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     motor-order  radius_cm  theta_rad   start_time     end_time  \\\n",
       "1              2        3.0   3.769911   373.644122   379.916842   \n",
       "3              1        4.5   2.932153   393.629486   399.856306   \n",
       "5              2        3.0   4.188790   413.651050   419.874370   \n",
       "7              1        6.0   2.094395   433.669214   439.885334   \n",
       "9              1        6.0   2.094395   453.688279   459.902599   \n",
       "..           ...        ...        ...          ...          ...   \n",
       "567            2        4.5   4.188790  6037.224098  6043.442118   \n",
       "569            1        6.0   2.932153  6057.243863  6063.453583   \n",
       "571            2        3.0   4.188790  6077.252527  6083.469447   \n",
       "573            1        3.0   2.094395  6097.261791  6103.471711   \n",
       "575            2        4.5   4.188790  6117.270755  6123.486175   \n",
       "\n",
       "     approach-end  depart-start  \n",
       "1      373.844122    379.716841  \n",
       "3      393.829387    399.656305  \n",
       "5      413.850951    419.674369  \n",
       "7      433.869215    439.685334  \n",
       "9      453.888279    459.702698  \n",
       "..            ...           ...  \n",
       "567   6037.424099   6043.242118  \n",
       "569   6057.443763   6063.253582  \n",
       "571   6077.452427   6083.269446  \n",
       "573   6097.461792   6103.271710  \n",
       "575   6117.470756   6123.286175  \n",
       "\n",
       "[288 rows x 7 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _register_df_times(df, barcode_signal_npx, barcode_signal_nidaqx):\n",
    "    \"\"\"Convert the times in the dataframe to the barcode signal times.\"\"\"\n",
    "    df = df.copy()\n",
    "    column_to_fix = [c for c in df.columns if \"bnc-time\" in c]\n",
    "    new_timename = \"\"\n",
    "\n",
    "    for c in column_to_fix:\n",
    "        new_colname = c.replace(\"_bnc-time\", new_timename)\n",
    "        df[new_colname] = barcode_signal_nidaqx.map_times_to(barcode_signal_npx, df[c].values)\n",
    "        df.drop(c, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _check_datetime_consistency_and_drop(df, oephys_datetime):\n",
    "    \"\"\"Assert that the datetime columns in the dataframe are consistent with the oephys datetime.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Convert \"serial-timestamp\" to datetime:\n",
    "    df[\"serial-timestamp\"] = pd.to_datetime(df[\"serial-timestamp\"])\n",
    "    \n",
    "    # check timestamp of rows with the sum between ephys datetime and the npx-time column:\n",
    "    npx_onsets_datetimes = df[\"start_time\"].apply(lambda x: oephys_datetime + timedelta(seconds=x))\n",
    "    assert all(abs((npx_onsets_datetimes - df[\"serial-timestamp\"]).dt.total_seconds().values < 1)), \"Timestamps do not match\"\n",
    "\n",
    "    return df.drop(\"serial-timestamp\", axis=1)\n",
    "\n",
    "\n",
    "motor_log_df = _load_motor_log_csv(data_folder, digital_signals[\"motor\"])\n",
    "motor_log_df = _register_df_times(motor_log_df, barcode_signal_npx, barcode_signal_nidaqx)\n",
    "motor_log_df = _check_datetime_consistency_and_drop(motor_log_df, oephys_datetime)\n",
    "motor_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames and triggers do not match exactly for TopCamera (537292 frames, 536848 triggers); estimating...\n",
      "Excluding final triggers\n"
     ]
    }
   ],
   "source": [
    "def _load_frames_csv(camera_name):\n",
    "    frames_trigger_df = pd.read_csv(_find_in_folder(data_folder, f\"{camera_name}*timestamps*.csv\"))\n",
    "    frames_trigger_df.rename(columns={\"Timestamp\": \"serial-timestamp\"}, inplace=True)\n",
    "\n",
    "    digital_triggers = digital_signals[\"frames\"].onsets_times\n",
    "\n",
    "    # check if frames are one every one or one every two triggers:\n",
    "    n_frames = len(frames_trigger_df)\n",
    "    n_triggers = len(digital_triggers)\n",
    "\n",
    "    if n_frames == n_triggers:\n",
    "        print(f\"Frames and triggers match for {camera_name}\")\n",
    "    elif n_frames == n_triggers  // 2:\n",
    "        print(f\"Frames and triggers match for {camera_name} with half the triggers\")\n",
    "    else:\n",
    "        print(f\"Frames and triggers do not match exactly for {camera_name} ({n_frames} frames, {n_triggers} triggers); estimating...\")\n",
    "        skip_frames = abs(n_frames - n_triggers // 2) < abs(n_frames - n_triggers)\n",
    "        \n",
    "        if skip_frames:\n",
    "            print(f\"Skipping every second trigger for {camera_name}\")\n",
    "            digital_triggers = digital_triggers[::2]\n",
    "        \n",
    "        n_triggers = len(digital_triggers)\n",
    "        if n_frames < n_triggers:\n",
    "            print(f\"More triggers than frames, truncating triggers to match frames\")\n",
    "            digital_triggers = digital_triggers[:n_frames]\n",
    "        else:\n",
    "            print(f\"More frames than triggers, truncating frames to match triggers\")\n",
    "            frames_trigger_df = frames_trigger_df.iloc[:n_triggers]\n",
    "       \n",
    "        digital_triggers = digital_triggers[:n_frames]\n",
    "\n",
    "    # frames_trigger_df[\"trigger_bnc-time\"] = digital_triggers\n",
    "\n",
    "    return frames_trigger_df\n",
    "\n",
    "for camera_name in [\"TopCamera\"]:#, \"EyeCamera\"]:\n",
    "    df = _load_frames_csv(camera_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert serial-timestamp to datetime:\n",
    "df[\"serial-timestamp\"] = pd.to_datetime(df[\"serial-timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdiff = df[\"serial-timestamp\"].diff().dt.total_seconds()\n",
    "tdiff_triggers = np.diff(digital_signals[\"frames\"].onsets_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate timings looking at laser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    laser_mean = np.load(data_folder / \"laser_mean_cache.npy\")\n",
    "except FileNotFoundError:\n",
    "    from bonpy import OpenCVMovieData\n",
    "    mov_data = OpenCVMovieData(\"/Users/vigji/Desktop/test_mpa_dir/P02_MPAOPTO_LP/e02_ephys-contrapag-stim/M21/20240421/165242/TopCamera__video_2024-04-21T16_52_14.avi\")\n",
    "\n",
    "    laset_mov = mov_data[:, 273:296, 423:450]\n",
    "    laser_mean = np.mean(laset_mov, axis=(1, 2))\n",
    "    np.save(data_folder / \"laser_mean_cache.npy\", laser_mean)\n",
    "\n",
    "laser_mean_cut = laser_mean[:len(digital_signals[\"frames\"].onsets_times)]\n",
    "laser_signal = digital_signals[\"laser\"]\n",
    "x_array = np.arange(len(laser_signal.array)) / laser_signal.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_plots=False\n",
    "if debug_plots:\n",
    "    f = plt.figure(figsize=(12, 5))\n",
    "    plt.plot(x_array, laser_signal.array+1, label=\"laser command\")\n",
    "    plt.plot(digital_signals[\"frames\"].offsets_times, laser_mean_cut[:-1]/100, c=\"r\", label=\"laser fiber pixel intensity\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    # f.savefig(fig_folder / \"laser_command.png\")\n",
    "    # plt.xlim(373.5, 374)\n",
    "    f.savefig(fig_folder / \"laser_command_begin.png\")\n",
    "    plt.xlim(6097.2, 6097.7)\n",
    "    f.savefig(fig_folder / \"laser_command_end.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
